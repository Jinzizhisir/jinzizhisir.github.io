---
layout: page
title: About
permalink: /index.html
---

<img style="float:right; padding-left:10px" src="images/self.jpeg" width="220" height="220">

I am a third-year Ph.D. student in computer science at Princeton University, advised by [Karthik Narasimhan](https://www.cs.princeton.edu/~karthikn/). Previously, I graduated from Yao Class at Tsinghua University.

My research interests include language, reinforcement, representation learning and their interplays, e.g. enabling [language models to act in interactive games](#CALM) or [game agents to evolve communications resembling language](#EC). 
The vision is to connect general-purpose representations (language) and general-purpose task-solving (RL) for challenging problems requiring [semantic](#Blindfold) inductive bias and flexible adaption/[exploration](#XTX).

<!-- The goal is twofold: to leverage language priors for grounded and interactive tasks, and to leverage such domains for more functional and  langauge modeling. -->

My personal interests include reading, basketball, pool, travel, and rap. 


# Papers

- <div id="EC"></div> **Linking Emergent and Natural Languages via Corpus Transfer**.
Shunyu Yao, Mo Yu, Yang Zhang, Karthik Narasimhan, Joshua Tenenbaum, Chuang Gan.
___ICLR 2022 (Spotlight)___. [[pdf](https://openreview.net/pdf?id=49A1Y6tRhaq)] [[code](https://github.com/ysymyth/ec-nl)]

- <div id="XTX"></div> **Multi-Stage Episodic Control for Strategic Exploration in Text Games**.
Jens Tuyls, Shunyu Yao, Sham Kakade, Karthik Narasimhan.
___ICLR 2022 (Spotlight)___. [[pdf](https://arxiv.org/pdf/2201.01251.pdf)] [[code](https://github.com/princeton-nlp/XTX)] [[project](https://sites.google.com/princeton.edu/xtx)]


- **Self-Attention Networks Can Process Bounded Hierarchical Languages**.
Shunyu Yao, Binghui Peng, Christos Papadimitriou, Karthik Narasimhan.
___ACL 2021___. [[pdf](https://arxiv.org/pdf/2105.11115.pdf)] [[code](https://github.com/princeton-nlp/dyck-transformer)]

- <div id="Blindfold"></div> **Reading and Acting while Blindfolded: The Need for Semantics in Text Game Agents**.
Shunyu Yao, Karthik Narasimhan, Matthew Hausknecht.
___NAACL 2021___. [[pdf](https://arxiv.org/pdf/2103.13552.pdf)] [[code](https://github.com/princeton-nlp/blindfold-textgame)] [[project](https://blindfolded.cs.princeton.edu)] [[MSR blogpost](https://www.microsoft.com/en-us/research/blog/building-stronger-semantic-understanding-into-text-game-reinforcement-learning-agents/)]

- <div id="CALM"></div> **Keep CALM and Explore: Language Models for Action Generation in Text-based Games**.
Shunyu Yao, Rohan Rao, Matthew Hausknecht, Karthik Narasimhan.
___EMNLP 2020___. [[pdf](https://arxiv.org/pdf/2010.02903.pdf)] [[code](https://github.com/princeton-nlp/calm-textgame)]

- **The Fine Structure of Surprise in Intuitive Physics: When, Why, and How Much?**.
Kevin Smith, Lingjie Mei, Shunyu Yao, Jiajun Wu, Elizabeth S. Spelke, Joshua B. Tenenbaum, Tomer D. Ullman.
___CogSci 2020___.
[[pdf](https://ysymyth.github.io/papers/surprise_cogsci.pdf)]

- **Modeling Expectation Violation in Intuitive Physics with Coarse Probabilistic Object Representations**.
Kevin Smith\*, Lingjie Mei\*, Shunyu Yao\*, Jiajun Wu, Elizabeth S. Spelke, Joshua B. Tenenbaum, Tomer D. Ullman.
___NeurIPS 2019___.
[[pdf](http://papers.neurips.cc/paper/9100-modeling-expectation-violation-in-intuitive-physics-with-coarse-probabilistic-object-representations.pdf)]
[[code](https://github.com/JerryLingjieMei/ADEPT-Model-Release)]
[[data](https://github.com/JerryLingjieMei/ADEPT-Dataset-Release)]
[[project](http://physadept.csail.mit.edu)]
[[MIT news](http://news.mit.edu/2019/adept-ai-machines-laws-physics-1202)]


- **3D-aware Scene Manipulation via Inverse Graphics**.
Shunyu Yao\*, Tzu-Ming Harry Hsu\*, Jun-Yan Zhu, Jiajun Wu, Antonio Torralba, William T. Freeman, Joshua B. Tenenbaum.
___NeurIPS 2018___.
[[pdf](http://papers.neurips.cc/paper/7459-3d-aware-scene-manipulation-via-inverse-graphics.pdf)]
[[code](https://github.com/ysymyth/3D-SDN)]
[[project](http://3dsdn.csail.mit.edu)]