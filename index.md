---
layout: page
title: About
permalink: /index.html
---

<img style="float:right; padding-left:10px" src="images/self.jpeg" width="220" height="220">

I am a third-year Ph.D. student in computer science at Princeton University, advised by [Karthik Narasimhan](https://www.cs.princeton.edu/~karthikn/). Previously, I graduated from Yao Class at Tsinghua University.

<!-- My research interests include language, reinforcement, representation learning and their interplays, e.g. enabling language models to act in interactive games [EMNLP'20], or game agents to evolve communications resembling language [ICLR'22 (1)]. 
The vision is to connect general-purpose representations (language) and general-purpose task-solving (RL), for challenging problems requiring semantic [NAACL'21] inductive bias plus flexible adaption and exploration [ICLR'22 (2)].
 -->


My research interests include language, reinforcement, representation learning and their interplays, e.g. enabling [language models to act in interactive games](https://arxiv.org/abs/2010.02903) or [game agents to evolve communications resembling language](http://arxiv.org/abs/2203.13344). 
The vision is to connect general-purpose representations (language) and general-purpose task-solving (RL), for challenging problems requiring [semantic](https://arxiv.org/abs/2103.13552) inductive bias plus flexible adaption and [exploration](https://arxiv.org/abs/2201.01251).


<!-- The goal is twofold: to leverage language priors for grounded and interactive tasks, and to leverage such domains for more functional and  langauge modeling. -->

My personal interests include reading, basketball, pool, travel, and rap. 


# Papers

- 
    **Linking Emergent and Natural Languages via Corpus Transfer** <br>
    Shunyu Yao, Mo Yu, Yang Zhang, Karthik Narasimhan, Joshua Tenenbaum, Chuang Gan <br>
    ICLR 2022 (Spotlight) 
    [paper](http://arxiv.org/abs/2203.13344) | 
    [code](https://github.com/ysymyth/ec-nl)


- 
    **Multi-Stage Episodic Control for Strategic Exploration in Text Games** <br>
    Jens Tuyls, Shunyu Yao, Sham Kakade, Karthik Narasimhan <br>
    ICLR 2022 (Spotlight) 
    [paper](https://arxiv.org/abs/2201.01251) | 
    [code](https://github.com/princeton-nlp/XTX) | 
    [project](https://sites.google.com/princeton.edu/xtx)


- **Self-Attention Networks Can Process Bounded Hierarchical Languages** <br>
    Shunyu Yao, Binghui Peng, Christos Papadimitriou, Karthik Narasimhan <br>
    ACL 2021 
    [paper](https://arxiv.org/abs/2105.11115) | 
    [code](https://github.com/princeton-nlp/dyck-transformer)

- **Reading and Acting while Blindfolded: The Need for Semantics in Text Game Agents** <br>
    Shunyu Yao, Karthik Narasimhan, Matthew Hausknecht <br>
    NAACL 2021 
    [paper](https://arxiv.org/abs/2103.13552) | 
    [code](https://github.com/princeton-nlp/blindfold-textgame) |
    [project](https://blindfolded.cs.princeton.edu) | 
    [MSR blogpost](https://www.microsoft.com/en-us/research/blog/building-stronger-semantic-understanding-into-text-game-reinforcement-learning-agents/)

- **Keep CALM and Explore: Language Models for Action Generation in Text-based Games** <br>
    Shunyu Yao, Rohan Rao, Matthew Hausknecht, Karthik Narasimhan <br>
    EMNLP 2020 
    [paper](https://arxiv.org/abs/2010.02903) | 
    [code](https://github.com/princeton-nlp/calm-textgame)

- **The Fine Structure of Surprise in Intuitive Physics: When, Why, and How Much?** <br>
Kevin Smith, Lingjie Mei, Shunyu Yao, Jiajun Wu, Elizabeth Spelke, Joshua Tenenbaum, Tomer Ullman <br>
CogSci 2020 
[paper](https://ysymyth.github.io/papers/surprise_cogsci.pdf)

- **Modeling Expectation Violation in Intuitive Physics with Coarse Probabilistic Object Representations** <br>
Kevin Smith\*, Lingjie Mei\*, Shunyu Yao\*, Jiajun Wu, Elizabeth Spelke, Joshua Tenenbaum, Tomer Ullman <br>
NeurIPS 2019 
[paper](http://papers.neurips.cc/paper/9100-modeling-expectation-violation-in-intuitive-physics-with-coarse-probabilistic-object-representations.pdf) | 
[code](https://github.com/JerryLingjieMei/ADEPT-Model-Release) | 
[data](https://github.com/JerryLingjieMei/ADEPT-Dataset-Release) |
[project](http://physadept.csail.mit.edu) | 
[MIT news](http://news.mit.edu/2019/adept-ai-machines-laws-physics-1202)

- **3D-aware Scene Manipulation via Inverse Graphics** <br>
Shunyu Yao\*, Tzu-Ming Harry Hsu\*, Jun-Yan Zhu, Jiajun Wu, Antonio Torralba, William Freeman, Joshua Tenenbaum <br>
NeurIPS 2018 
[paper](https://arxiv.org/abs/1808.09351) | 
[code](https://github.com/ysymyth/3D-SDN) | 
[project](http://3dsdn.csail.mit.edu)


# Readings
Some recent readings of mine in random orders:
* 废都（贾平凹）
* 生死疲劳（莫言）
* 故事新编（鲁迅）
* Principles (Ray Dalio)
* Who Says Elephants Can't Dance (Louis Gerstner)
* Hit Refresh (Satya Nadella)
* The Buried Giant (Kazuo Ishiguro)
* How Language Began: The Story of Humanity's Greatest Invention (Daniel Everett)
* The Linguistics Wars (Randy Allen Harris)
<!-- <div id="CALM"></div> -->

<!-- My research interests include language, reinforcement, representation learning and their interplays, e.g. enabling [language models to act in interactive games](#CALM) or [game agents to evolve communications resembling language](#EC).  -->
<!-- The vision is to connect general-purpose representations (language) and general-purpose task-solving (RL) for challenging problems requiring [semantic](#Blindfold) inductive bias and flexible adaption/[exploration](#XTX). -->
